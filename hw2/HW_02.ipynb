{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема “Создание признакового пространства”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PREP_DATA = '../data/prep_tweets.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим подготовленный датасет твиттов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = pd.read_pickle(PREP_DATA)\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Создайте мешок слов с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_docs = df_prep['tweet_stemmed'].apply(' '.join)\n",
    "\n",
    "lemmatized_docs = df_prep['tweet_lemmatized'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_bagbag_of_words(vectorizer: object, docs: list) -> object:\n",
    "    \n",
    "    bag_of_words = vectorizer.fit_transform(docs)\n",
    "    \n",
    "    # Отобразим Bag-of-Words модель как DataFrame\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return pd.DataFrame(bag_of_words.toarray(), columns = feature_names).copy()\n",
    "\n",
    "\n",
    "def make_bagbag_of_words_simple(docs: list) -> object:\n",
    "   \n",
    "    count_vectorizer = CountVectorizer(max_df=0.9, max_features = 1000, stop_words='english')\n",
    "    return _make_bagbag_of_words(count_vectorizer, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual  ad  ...  \\\n",
       "0    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "1    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "2    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmed\n",
    "stemmed_bow = make_bagbag_of_words_simple(stemmed_docs)\n",
    "stemmed_bow.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_bow.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0     0           0       0        0    0       0      0         0      0   \n",
       "1     0           0       0        0    0       0      0         0      0   \n",
       "2     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "   add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  yummy  \n",
       "0    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "1    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "2    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatized\n",
    "lemmatized_bow = make_bagbag_of_words_simple(lemmatized_docs)\n",
    "lemmatized_bow.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204283"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_bow.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Создайте мешок слов с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bagbag_of_words_tfidf(docs: list) -> object:\n",
    "   \n",
    "    vectorizer = TfidfVectorizer(max_df=0.9, max_features = 1000, stop_words='english')\n",
    "    return _make_bagbag_of_words(vectorizer, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual   ad  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmed\n",
    "stemmed_tfidf = make_bagbag_of_words_tfidf(stemmed_docs)\n",
    "stemmed_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93434.75975058634"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_tfidf.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "1   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "2   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "\n",
       "   add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
       "0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "   yummy  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatized\n",
    "lemmatized_tfidf = make_bagbag_of_words_tfidf(lemmatized_docs)\n",
    "lemmatized_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90534.85481794423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tfidf.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Натренируем gensim.models.Word2Vec модель на наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, is, dysfunctional, and, is, so,...\n",
       "1    [thanks, for, lyft, credit, can, not, use, cau...\n",
       "2                              [bihday, your, majesty]\n",
       "3    [model, love, you, take, with, you, all, the, ...\n",
       "4               [factsguide, society, now, motivation]\n",
       "Name: tweet_token, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs = df_prep['tweet_token']\n",
    "tokenized_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 92.6 ms, total: 1min 10s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v = Word2Vec(tokenized_docs, \n",
    "              size=200, \n",
    "              window=5, \n",
    "              min_count=2, \n",
    "              sg = 1, \n",
    "              hs = 0, \n",
    "              negative = 10, \n",
    "              workers= 32, \n",
    "              seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 55s, sys: 432 ms, total: 3min 55s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9140310, 11726520)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v.train(tokenized_docs, total_examples=tokenized_docs.size, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### потестируем нашу модель Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bihdaydinner: 0.5573\n",
      "[('bihdaydinner', 0.5572851896286011), ('spaghetti', 0.555306077003479), ('bolognese', 0.550733745098114)]\n"
     ]
    }
   ],
   "source": [
    "# выведим слово наиболее близкое к 'dinner'\n",
    "result = model_w2v.most_similar(positive=['dinner'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))\n",
    "print(model_w2v.similar_by_word(\"dinner\", topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald: 0.5575\n",
      "[('donald', 0.5575395226478577), ('suppoer', 0.5285787582397461), ('crony', 0.5265582203865051)]\n"
     ]
    }
   ],
   "source": [
    "# выведим слово наиболее близкое к 'trump'\n",
    "result = model_w2v.most_similar(positive=['trump'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))\n",
    "print(model_w2v.similar_by_word(\"trump\", topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### проверим векторное представление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09265701, -0.07108294, -0.39404234,  0.3836512 ,  0.28662294,\n",
       "       -0.05926029,  0.28960693,  0.66081566,  0.05989827,  0.15868618,\n",
       "       -0.31925347, -0.34518752, -0.04214924, -0.21273781,  0.1769759 ,\n",
       "       -0.40478966, -0.44924566,  0.34910938, -0.15762265,  0.6244696 ,\n",
       "        0.32853493, -0.1739553 ,  0.00730438,  0.10333357, -0.08920829,\n",
       "        0.31456622, -0.43091068, -0.70993495, -0.7917362 ,  0.13339871,\n",
       "       -0.3066326 , -0.16108833, -0.5332007 , -0.64329714, -0.5787214 ,\n",
       "        0.285422  ,  0.16875497,  0.01981907, -0.389986  , -0.08095073,\n",
       "        0.2067487 , -0.15445949,  0.19391172, -0.27844563,  0.23882854,\n",
       "        0.26701686, -0.84153545,  0.40209776,  0.23610052,  0.08376999,\n",
       "        0.45181605, -0.41420588,  0.5227954 , -0.19663644, -0.10757492,\n",
       "        0.04713054,  0.30724207, -0.3553161 ,  0.51247734, -0.3945258 ,\n",
       "        0.41556054, -0.31315154,  0.62057364,  0.8672947 ,  0.32127017,\n",
       "       -0.7993134 ,  0.05582834,  0.09274858,  0.22257322,  0.20785269,\n",
       "        0.09252589, -0.37730885,  0.16750242, -0.34763047,  0.1269944 ,\n",
       "       -0.1269856 , -0.18979302,  0.5013929 ,  0.08709175, -0.1198214 ,\n",
       "        0.08569581, -0.28647193, -0.08151931, -0.02681033, -0.4352893 ,\n",
       "       -0.6233625 ,  0.11348007, -0.23015082, -0.11343781,  0.5010247 ,\n",
       "       -0.73272866,  0.18667807, -0.03660813,  0.02350224,  0.1450808 ,\n",
       "        0.67382145, -0.27769977, -0.8482346 ,  0.4246147 ,  0.59125006,\n",
       "        0.03299882, -0.52135694, -0.18725094, -0.20283635, -0.15654181,\n",
       "       -0.54875517, -0.43834564, -0.27103874, -0.04308655,  0.09465896,\n",
       "       -0.15523574,  0.14582182,  0.3200762 ,  0.5206736 , -0.5706241 ,\n",
       "        1.1958889 ,  0.26181716, -0.35148215, -0.27004972, -0.06045433,\n",
       "        0.00453213,  0.00703311, -0.10265004,  0.23980153, -0.05184011,\n",
       "       -0.5392226 , -0.02540938,  0.0282018 , -0.45989114,  0.61532104,\n",
       "        0.09047671,  0.7524208 ,  0.42214394, -0.5731526 , -0.11515921,\n",
       "       -0.599521  , -0.17330247,  0.31405637,  0.04142815,  0.3787455 ,\n",
       "       -0.23113577,  0.02077624, -0.07713307, -0.28365138,  0.12850404,\n",
       "       -0.20995682,  0.01770396,  0.16501223,  0.11133394,  0.11708707,\n",
       "        0.45002395,  0.12441823, -0.40588158,  0.56190753, -0.39346373,\n",
       "       -0.08941898,  0.1513166 ,  0.49593568, -0.5274336 , -0.14364205,\n",
       "       -1.2206426 , -0.06938837, -0.08056509,  0.48181072,  0.7372083 ,\n",
       "       -0.93990076, -0.2747503 ,  0.6272264 , -0.7766001 , -0.21177346,\n",
       "        0.00506711, -0.13921887,  0.93361163,  0.28817743,  0.01181938,\n",
       "        0.36055714,  0.41240278, -0.08868144, -0.03428426, -0.28370345,\n",
       "       -0.7280145 ,  0.32680857,  0.7095807 , -0.01048089, -0.01527601,\n",
       "        0.55046594, -0.8131422 ,  0.6274098 , -0.8497714 , -0.5304933 ,\n",
       "        1.1157252 , -0.49217838, -0.434868  ,  0.6372186 ,  0.5772041 ,\n",
       "       -0.5565708 ,  0.39874673,  0.07306284,  0.8599694 , -0.45667338],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['tweet_token'].apply(lambda x: 'disapointed' in x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['food'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимо создать вектор для каждого твита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем вектора для каждого слова и затем усредняем\n",
    "def vectorize_tweet(words: list)-> list or None:\n",
    "    res = None\n",
    "    vec = []\n",
    "    for item in words:\n",
    "        try:\n",
    "            vec.append(model_w2v[item])\n",
    "        except KeyError as err:\n",
    "            pass\n",
    "    if len(vec)>0:\n",
    "        res =  np.average(vec, axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 79.9 ms, total: 11.5 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "v2w_tweets = tokenized_docs.apply(vectorize_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2w_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49139,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем наличие твитов состоящие из слов которых нет в нашем словаре\n",
    "print(v2w_tweets.isna().sum())\n",
    "# и удаляем их\n",
    "v2w_tweets.dropna(inplace=True)\n",
    "v2w_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>0.107611</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>-0.176435</td>\n",
       "      <td>-0.061256</td>\n",
       "      <td>0.125712</td>\n",
       "      <td>-0.076131</td>\n",
       "      <td>-0.050619</td>\n",
       "      <td>0.191050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327770</td>\n",
       "      <td>0.055676</td>\n",
       "      <td>-0.259871</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>0.158218</td>\n",
       "      <td>-0.163714</td>\n",
       "      <td>-0.022097</td>\n",
       "      <td>-0.150173</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.095538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106415</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>0.132153</td>\n",
       "      <td>0.044252</td>\n",
       "      <td>-0.134078</td>\n",
       "      <td>-0.091230</td>\n",
       "      <td>0.036257</td>\n",
       "      <td>-0.055944</td>\n",
       "      <td>-0.130872</td>\n",
       "      <td>0.211153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280244</td>\n",
       "      <td>0.120028</td>\n",
       "      <td>-0.348166</td>\n",
       "      <td>-0.036761</td>\n",
       "      <td>0.189935</td>\n",
       "      <td>-0.132732</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.026970</td>\n",
       "      <td>0.317535</td>\n",
       "      <td>-0.074957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435508</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>0.295512</td>\n",
       "      <td>-0.053668</td>\n",
       "      <td>0.354483</td>\n",
       "      <td>0.245542</td>\n",
       "      <td>0.392723</td>\n",
       "      <td>-0.513703</td>\n",
       "      <td>-0.088398</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363724</td>\n",
       "      <td>0.203380</td>\n",
       "      <td>-0.679096</td>\n",
       "      <td>0.175086</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>-0.193322</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.109717</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0.183119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.026038  0.075128  0.107611  0.101912 -0.176435 -0.061256  0.125712   \n",
       "1  0.106415  0.029637  0.132153  0.044252 -0.134078 -0.091230  0.036257   \n",
       "2  0.435508  0.037012  0.295512 -0.053668  0.354483  0.245542  0.392723   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.076131 -0.050619  0.191050  ...  0.327770  0.055676 -0.259871  0.032576   \n",
       "1 -0.055944 -0.130872  0.211153  ...  0.280244  0.120028 -0.348166 -0.036761   \n",
       "2 -0.513703 -0.088398 -0.084223  ... -0.363724  0.203380 -0.679096  0.175086   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.158218 -0.163714 -0.022097 -0.150173  0.391357  0.095538  \n",
       "1  0.189935 -0.132732  0.066449  0.026970  0.317535 -0.074957  \n",
       "2  0.105418 -0.193322  0.073542  0.109717  0.115645  0.183119  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df = pd.DataFrame.from_records(v2w_tweets)\n",
    "wordvec_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49139, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49139 entries, 0 to 49138\n",
      "Columns: 200 entries, 0 to 199\n",
      "dtypes: float64(200)\n",
      "memory usage: 75.0 MB\n"
     ]
    }
   ],
   "source": [
    "wordvec_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
